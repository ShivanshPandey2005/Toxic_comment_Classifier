#**üí¨ Toxic Comment Classifier**

Ever wondered how platforms detect harmful or offensive comments automatically? This project is a machine learning-based Toxic Comment Classifier that can recognize and label different types of toxic online behavior in user comments.

It‚Äôs built using Python, NLP techniques, and machine learning models ‚Äî trained on real-world data from the Jigsaw Toxic Comment Classification Challenge.

#**üîç What It Can Do**
This tool can automatically classify a comment into one or more of the following categories:

Toxic

Severely Toxic

Obscene

Threat

Insult

Identity Hate

It supports both command-line predictions and an optional web interface for live testing.

#**üß† How It Works**

**Text Preprocessing**: Clean and prepare comments using tokenization, stopword removal, etc.

**Model Training**: Use ML models like Logistic Regression, SVM, or even deep learning (LSTM/CNN).

**Prediction**: Classify new comments and flag them if they contain harmful content.

**Evaluation**: Visualize performance using accuracy, precision, recall, F1-score, and confusion matrices.

